{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Review : XOR\n",
    "- Multi Layer Perceptron\n",
    "- Backpropagation\n",
    "- Code : xor-nn\n",
    "- Code : xor-nn-wide-deep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XOR\n",
    "\n",
    "![](https://projectiot123.com/wp-content/uploads/2019/05/XOR-GATE.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이문제는 이전 09에서도 봤듯이 Single Layer로는 해결이 불가능하다.  \n",
    "고로 Multi Layer가 필요하다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 같이 말했지만 __Backpropagation__을 이용한다면??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backpropagtaion with Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "  \n",
    "# for reproducibility\n",
    "torch.manual_seed(777)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.6931471824645996\n",
      "100 0.6931471824645996\n",
      "200 0.6931471824645996\n",
      "300 0.6931471824645996\n",
      "400 0.6931471824645996\n",
      "500 0.6931471824645996\n",
      "600 0.6931471824645996\n"
     ]
    }
   ],
   "source": [
    "X = torch.FloatTensor([[0,0],[0,1],[1,0],[1,1]]).to(device)\n",
    "Y = torch.FloatTensor([[0],[1],[1],[0]]).to(device)\n",
    "\n",
    "## nn Layers\n",
    "w1 = torch.FloatTensor(2,2).to(device)\n",
    "b1 = torch.FloatTensor(2).to(device)\n",
    "w2 = torch.FloatTensor(2,1).to(device)\n",
    "b2 = torch.FloatTensor(1).to(device)\n",
    "learning_rate = 0.1\n",
    "\n",
    "def sigmoid(x) :\n",
    "    # sigmoid function\n",
    "    return 1.0 / (1.0 + torch.exp(-x))\n",
    "\n",
    "def sigmoid_prime(x) : \n",
    "    # derivative of the sigmoid function (도함수)\n",
    "    return sigmoid(x) * (1 - sigmoid(x)) \n",
    "\n",
    "for step in range(10001) :\n",
    "    # forward\n",
    "    l1 = torch.add(torch.matmul(X, w1), b1)\n",
    "    a1 = sigmoid(l1)\n",
    "    l2 = torch.add(torch.matmul(a1, w2), b2)\n",
    "    Y_pred = sigmoid(l2)\n",
    "    \n",
    "    # cost를 구하기 위해 Binary Cross Entropy Loss를 사용하기로 합니다. \n",
    "    cost = - torch.mean(Y * torch.log(Y_pred) + (1 - Y) * torch.log(1 - Y_pred))\n",
    "    \n",
    "    \n",
    "    # Back prop (chain rule)\n",
    "    # Loss derivative\n",
    "    \n",
    "    # Binary cross Entropy Loss에 대한 미분 \n",
    "    d_Y_pred = (Y_pred -Y) / (Y_pred * (1.0 - Y_pred) + 1e-7)\n",
    "    # 1e-7는 0이 나눠지는것을 방지하기위함\n",
    "    \n",
    "    # Layer 2\n",
    "    d_l2 = d_Y_pred * sigmoid_prime(l2)\n",
    "    d_b2 = d_l2\n",
    "    d_w2 = torch.matmul(torch.transpose(a1,0,1),d_b2)\n",
    "    # transpose 는 차원축을 정해서 Transpose 가능함\n",
    "    # (10,5) 를 torch.transpose(a1,0,1) 를 하면 (5,10)이된다.\n",
    "    \n",
    "    \n",
    "    # Layer 1\n",
    "    d_a1 = torch.matmul(d_b2, torch.transpose(w2,0,1))\n",
    "    d_l1 = d_a1 * sigmoid_prime(l1)\n",
    "    d_b1 = d_l1\n",
    "    d_w1 = torch.matmul(torch.transpose(X,0,1),d_b1)\n",
    "    \n",
    "    # Weight update \n",
    "    # Gradient descent minimize\n",
    "    w1 = w1 - learning_rate * d_w1\n",
    "    b1 = b1 - learning_rate * torch.mean(d_b1,0)\n",
    "    w2 = w2 - learning_rate * d_w2\n",
    "    b2 - b2 - learning_rate * torch.mean(d_b2,0)\n",
    "    \n",
    "    if step %100 == 0:\n",
    "        print(step,cost.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "안되는 것을 볼 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.8579397797584534\n",
      "100 0.6918308734893799\n",
      "200 0.6874244213104248\n",
      "300 0.6484621167182922\n",
      "400 0.5045989751815796\n",
      "500 0.4177666902542114\n",
      "600 0.3875471353530884\n",
      "700 0.3743336796760559\n",
      "800 0.3672516345977783\n",
      "900 0.362920880317688\n",
      "1000 0.3600276708602905\n"
     ]
    }
   ],
   "source": [
    "X = torch.FloatTensor([[0,0],[0,1],[1,0],[1,1]]).to(device)\n",
    "Y = torch.FloatTensor([[0],[1],[1],[0]]).to(device)\n",
    "\n",
    "# nn Layer\n",
    "linear1 = torch.nn.Linear(2,2, bias=True)\n",
    "linear2 = torch.nn.Linear(2,1, bias=True) \n",
    "sigmoid = torch.nn.Sigmoid()\n",
    "model = torch.nn.Sequential(linear1, sigmoid , linear2, sigmoid).to(device)\n",
    "\n",
    "# define cost/loss $ optimizer\n",
    "criterion = torch.nn.BCELoss().to(device) # X값이 0,1과 1을 분리하는 Binary Classification Task 이므로 Loss로는 Binary Cross Entropy Loss를 사용합니다.\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1)\n",
    "# Optimizer로는 이전에도 이용하는 statistic gradient descent를 사용\n",
    "\n",
    "for step in range(1001) :\n",
    "    optimizer.zero_grad()\n",
    "    hypothesis = model(X)\n",
    "    \n",
    "    # cost/loss function\n",
    "    cost = criterion(hypothesis, Y)\n",
    "    # model이 X,Y 게이트와 같은 값이 나올수 있도록 학습\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    if step % 100 == 0 :\n",
    "        print(step, cost.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 성공"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "응용해서 3개 4개의 Multi Layer또한 구성 가능하다"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
