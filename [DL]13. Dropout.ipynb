{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropout\n",
    "\n",
    "- Overfitting\n",
    "- Dropout\n",
    "- Code : mnist_nn_dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overfitting ( 과적합 )\n",
    "\n",
    "![fit](https://miro.medium.com/max/1125/1*_7OPgojau8hkiPUiHoGK_w.png)\n",
    "\n",
    "물론 fitting에 대한 개인차는 존재합니다.  \n",
    "하지만 기계학습측면에서  \n",
    "Underfitting은 학습이 덜되었다 또는, 낮은 차원의 모델을 사용한다는 문제를 갖고 있습니다.  \n",
    "\n",
    "Overfitting에 관해서는 학습 모델에만 맞췄다는 문제와 너무 고차원의 모델을 사용한다는 문제가 있습니다.  \n",
    "\n",
    "하지만,여기서 Overfitting에 대해서 궁금증이 생깁니다. 완벽하게 학습을 하면 더 좋지 않을까라는 궁금증입니다. 이제 이 의문점에 대해 알아보도록 하겠습니다.\n",
    "\n",
    "위의 그림을 보면 학습과정에서 100% 완벽한 모습을 가진 모델이 Test에서는 생각보다 그렇지 못한 모습을 보이고 있습니다.  \n",
    "이는 Test와 Train set과의 차이가 존재하기 떄문입니다.  \n",
    "그래서 이러한 overfitting된 모델은 더 큰 에러를 발생시킬수 있습니다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solutions for Overfitting\n",
    "\n",
    "- More training data\n",
    "- Reduce the number of features\n",
    "- Regularization\n",
    "- __Dropout__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout\n",
    "\n",
    "학습을 진행하면서 레이어에 존재하는 노드(뉴런)들을 설정된 비율에 따라 on/off 를 진행하는 것이라고 합니다.  \n",
    "\n",
    "여기서 중요한것은 비율은 정하지만 랜덤하게 노드들을 정한다는 것 입니다.  \n",
    "이러한 모델의 장점으로는 Overfitting을 막는것을 더해 다른 형태의 네트워크를 다른 결과를 만들어 학습할 수 있다는 네트워크 앙상블 효과또한 얻을수 있어 학습효과를 높일수도 있다는 장점이 있다고 합니다. \n",
    "\n",
    "![dropout](https://miro.medium.com/proxy/1*iWQzxhVlvadk6VAJjsgXgg.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
