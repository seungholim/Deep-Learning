{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate Linear Regression\n",
    "\n",
    "- Simple Linear Regression 복습\n",
    "- Multiavriate Linear Regression 이론\n",
    "- Naive Data Representation\n",
    "- Matrix Data Representation\n",
    "- Multivariate Linear Regression\n",
    "- nn.Module 소개\n",
    "- F.mse_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "지금까지 Simple Linear Regression 은 하나의 정보로 부터 하나의 결론을 짖는 모델이였습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "하지만, 다양한 문제를 풀기 위해선 이러한 하나의 정보론 결과를 얻을수가 없습니다.  \n",
    "그렇기에 이제부터 Multiariate Linear Regression 에 대해 알아보도록 하겠습니다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate Linear Regression\n",
    "\n",
    "복수의 정보가 들어왔을때 하나의 정보를 추측하기  \n",
    "ex) 3번의 쪽지시험 결과를 통해 기말고사 예측하기 \n",
    "\n",
    "| quiz1 | quiz2 | quiz3 | Final(y) |\n",
    "|-------|-------|-------|----------|\n",
    "| 73    | 80    | 75    | 152      |\n",
    "| 93    | 88    | 93    | 185      |\n",
    "| 89    | 91    | 80    | 180      |\n",
    "| 73    | 66    | 70    | 142       |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.FloatTensor([[73,80,75],[93,88,93],[89,91,80],[73,66,70]])\n",
    "y_train = torch.FloatTensor([[152],[185],[180],[142]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis Function\n",
    "\n",
    "H(x) = Wx + b\n",
    "- x라는 vector와 W라는 matrix의 곱\n",
    "\n",
    "H(X) = w1x1 + w2x2 + w3x3 + b\n",
    "\n",
    "위와 같이 x의 값이 적을떄는 hypothesis를 그냥 곱으로 구할 수 있지만 100개 1000개 10000개가 넘어가면 힘들다 .  \n",
    "그럴떈 matmul()로 한번에 계산한다.  \n",
    "\n",
    "matmul() 특징\n",
    "- 간결하다.\n",
    "- x의 길이가 바껴도 코드를 바꿀 필요가 없다\n",
    "- 속도가 빠르다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hypothesis = x_train.matmul(W) + b # or .mm or @ 를 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multivariate Linear Regression 또한 Cost function을 구하는 공식은 기존 Simple Linear Regression과 동일하다.  \n",
    "\n",
    "cost = torch.mean((hypothesis - y_train) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Code with torch.optim(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/20 hypothesis: tensor([0., 0., 0., 0.]) cost : 27473.250000\n",
      "Epoch    1/20 hypothesis: tensor([61.4952, 73.8967, 70.1744, 56.3782]) cost : 9981.958984\n",
      "Epoch    2/20 hypothesis: tensor([ 98.5568, 118.4321, 112.4670,  90.3558]) cost : 3628.820801\n",
      "Epoch    3/20 hypothesis: tensor([120.8928, 145.2724, 137.9560, 110.8333]) cost : 1321.251099\n",
      "Epoch    4/20 hypothesis: tensor([134.3540, 161.4482, 153.3179, 123.1745]) cost : 483.100830\n",
      "Epoch    5/20 hypothesis: tensor([142.4667, 171.1967, 162.5765, 130.6121]) cost : 178.669479\n",
      "Epoch    6/20 hypothesis: tensor([147.3559, 177.0718, 168.1566, 135.0946]) cost : 68.093681\n",
      "Epoch    7/20 hypothesis: tensor([150.3024, 180.6123, 171.5200, 137.7960]) cost : 27.929579\n",
      "Epoch    8/20 hypothesis: tensor([152.0781, 182.7460, 173.5473, 139.4240]) cost : 13.339922\n",
      "Epoch    9/20 hypothesis: tensor([153.1482, 184.0317, 174.7694, 140.4052]) cost : 8.039693\n",
      "Epoch   10/20 hypothesis: tensor([153.7930, 184.8064, 175.5062, 140.9964]) cost : 6.113406\n",
      "Epoch   11/20 hypothesis: tensor([154.1815, 185.2731, 175.9506, 141.3527]) cost : 5.412576\n",
      "Epoch   12/20 hypothesis: tensor([154.4156, 185.5542, 176.2187, 141.5674]) cost : 5.156903\n",
      "Epoch   13/20 hypothesis: tensor([154.5566, 185.7234, 176.3806, 141.6967]) cost : 5.062884\n",
      "Epoch   14/20 hypothesis: tensor([154.6415, 185.8252, 176.4785, 141.7746]) cost : 5.027605\n",
      "Epoch   15/20 hypothesis: tensor([154.6925, 185.8864, 176.5377, 141.8215]) cost : 5.013647\n",
      "Epoch   16/20 hypothesis: tensor([154.7232, 185.9231, 176.5738, 141.8497]) cost : 5.007420\n",
      "Epoch   17/20 hypothesis: tensor([154.7416, 185.9450, 176.5958, 141.8667]) cost : 5.004047\n",
      "Epoch   18/20 hypothesis: tensor([154.7526, 185.9581, 176.6093, 141.8768]) cost : 5.001652\n",
      "Epoch   19/20 hypothesis: tensor([154.7592, 185.9658, 176.6178, 141.8829]) cost : 4.999661\n",
      "Epoch   20/20 hypothesis: tensor([154.7630, 185.9703, 176.6232, 141.8866]) cost : 4.997797\n"
     ]
    }
   ],
   "source": [
    "# 데이터\n",
    "x_train = torch.FloatTensor([[73,80,75],\n",
    "                             [93,88,93],\n",
    "                             [89,91,80],\n",
    "                             [73,66,70]])\n",
    "y_train = torch.FloatTensor([[152],[185],[180],[142]])\n",
    "\n",
    "# 모델의 초기화 (기존과 W가 바뀜)\n",
    "W = torch.zeros((3,1), requires_grad = True)\n",
    "b = torch.zeros(1, requires_grad = True)\n",
    "\n",
    "# optimizer 설정 (기존과 [W,b] 이 변경됌)\n",
    "optimizer = torch.optim.SGD([W,b], lr=1e-5)\n",
    "\n",
    "nb_epochs = 20\n",
    "\n",
    "for epoch in range(nb_epochs+1) :\n",
    "    hypothesis = x_train.matmul(W) + b\n",
    "    \n",
    "    # cost 계산\n",
    "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
    "    \n",
    "    # cost로 H(x) 개선\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    print('Epoch {:4d}/{} hypothesis: {} cost : {:6f}'.format(\n",
    "        epoch, nb_epochs, hypothesis.squeeze().detach(), cost.item()\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6895],\n",
       "        [0.6825],\n",
       "        [0.6643]], requires_grad=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost\n",
    "W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위와 같이 구하는 방법도 있지만, 계속해서 W와 b를 구하는건 귀찮은 일입니다.  \n",
    "pytorch는 이런점을 해결하기위해 nn.Module를 제공합니다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.Module\n",
    "\n",
    "- nn.Module 을 상속해서 모델 생성\n",
    "- nn.Linear(3, 1)\n",
    "    - 입력 차원 : 3\n",
    "    - 출력 차원 : 1\n",
    "- Hypothesis 계산은 foward()에서 !\n",
    "- Gradient 계산은 Pytorch가 알아서 해준다 backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class MultivariateLinearRegressionModel(nn.Module) :\n",
    "    def __init__(self) :\n",
    "        super().__init__()\n",
    "        self.linear = nn.linear(3,1)\n",
    "        \n",
    "    def forward(self, x) :\n",
    "        return self.linear(x)\n",
    "    \n",
    "hypothesis = model(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.nn.functional\n",
    "\n",
    "##### F.mse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost 계산\n",
    "cost = cost = torch.mean((hypothesis - y_train) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "를 torch.nn.functional 모듈을 이용하면 편하게 계산 가능하다.  \n",
    "\n",
    "이렇게 이용하면 가독성과 유지보수가 편하다.  \n",
    "또한 다른 loss_function들로 교체가 간단하다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "# cost 계산\n",
    "\n",
    "cost = F.mse_loss(prediction, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Code with torch.optim(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# H(x) 계산\n",
    "# hypothesis = x_train.matmul(W) + b\n",
    "Hypothesis = model(x_train)\n",
    "\n",
    "\n",
    "# cost 계산\n",
    "# cost = torch.mean((hypothesis - y_train) ** 2)\n",
    "cost = F.mse_loss(prediction, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "들로 변경한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
